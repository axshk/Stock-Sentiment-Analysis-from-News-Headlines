{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gnikita-pro/Stock-Sentiment-Analysis-from-News-Headlines/blob/main/STOCK_SHARE_PREDICTOR.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3D8TGpraE3BM",
        "outputId": "4b44a0ff-ab11-4e3c-a5a5-140eae84ebc6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QLkYiF5F_AxS"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dWSEcDBUJNY9",
        "outputId": "9750c103-1d09-4d64-9929-8980f7e72211"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting streamlit\n",
            "  Downloading streamlit-1.15.2-py2.py3-none-any.whl (9.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 9.2 MB 5.2 MB/s \n",
            "\u001b[?25hCollecting validators>=0.2\n",
            "  Downloading validators-0.20.0.tar.gz (30 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from streamlit) (1.21.6)\n",
            "Requirement already satisfied: pandas>=0.21.0 in /usr/local/lib/python3.8/dist-packages (from streamlit) (1.3.5)\n",
            "Collecting blinker>=1.0.0\n",
            "  Downloading blinker-1.5-py2.py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: requests>=2.4 in /usr/local/lib/python3.8/dist-packages (from streamlit) (2.23.0)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.8/dist-packages (from streamlit) (0.10.2)\n",
            "Collecting pydeck>=0.1.dev5\n",
            "  Downloading pydeck-0.8.0-py2.py3-none-any.whl (4.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.7 MB 39.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: altair>=3.2.0 in /usr/local/lib/python3.8/dist-packages (from streamlit) (4.2.0)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.8/dist-packages (from streamlit) (7.1.2)\n",
            "Collecting watchdog\n",
            "  Downloading watchdog-2.1.9-py3-none-manylinux2014_x86_64.whl (78 kB)\n",
            "\u001b[K     |████████████████████████████████| 78 kB 6.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.10.0.0 in /usr/local/lib/python3.8/dist-packages (from streamlit) (4.1.1)\n",
            "Requirement already satisfied: pyarrow>=4.0 in /usr/local/lib/python3.8/dist-packages (from streamlit) (9.0.0)\n",
            "Requirement already satisfied: protobuf<4,>=3.12 in /usr/local/lib/python3.8/dist-packages (from streamlit) (3.19.6)\n",
            "Requirement already satisfied: tzlocal>=1.1 in /usr/local/lib/python3.8/dist-packages (from streamlit) (1.5.1)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.8/dist-packages (from streamlit) (2.8.2)\n",
            "Collecting rich>=10.11.0\n",
            "  Downloading rich-12.6.0-py3-none-any.whl (237 kB)\n",
            "\u001b[K     |████████████████████████████████| 237 kB 79.1 MB/s \n",
            "\u001b[?25hCollecting pympler>=0.9\n",
            "  Downloading Pympler-1.0.1-py3-none-any.whl (164 kB)\n",
            "\u001b[K     |████████████████████████████████| 164 kB 64.6 MB/s \n",
            "\u001b[?25hCollecting semver\n",
            "  Downloading semver-2.13.0-py2.py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: tornado>=5.0 in /usr/local/lib/python3.8/dist-packages (from streamlit) (6.0.4)\n",
            "Requirement already satisfied: importlib-metadata>=1.4 in /usr/local/lib/python3.8/dist-packages (from streamlit) (4.13.0)\n",
            "Requirement already satisfied: cachetools>=4.0 in /usr/local/lib/python3.8/dist-packages (from streamlit) (5.2.0)\n",
            "Requirement already satisfied: packaging>=14.1 in /usr/local/lib/python3.8/dist-packages (from streamlit) (21.3)\n",
            "Collecting gitpython!=3.1.19\n",
            "  Downloading GitPython-3.1.29-py3-none-any.whl (182 kB)\n",
            "\u001b[K     |████████████████████████████████| 182 kB 76.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.8/dist-packages (from streamlit) (7.1.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from altair>=3.2.0->streamlit) (2.11.3)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.8/dist-packages (from altair>=3.2.0->streamlit) (4.3.3)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.8/dist-packages (from altair>=3.2.0->streamlit) (0.4)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.8/dist-packages (from altair>=3.2.0->streamlit) (0.12.0)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
            "\u001b[K     |████████████████████████████████| 62 kB 1.2 MB/s \n",
            "\u001b[?25hCollecting smmap<6,>=3.0.1\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=1.4->streamlit) (3.10.0)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema>=3.0->altair>=3.2.0->streamlit) (5.10.0)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema>=3.0->altair>=3.2.0->streamlit) (0.19.2)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema>=3.0->altair>=3.2.0->streamlit) (22.1.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=14.1->streamlit) (3.0.9)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=0.21.0->streamlit) (2022.6)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.8/dist-packages (from jinja2->altair>=3.2.0->streamlit) (2.0.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil->streamlit) (1.15.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.4->streamlit) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.4->streamlit) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.4->streamlit) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.4->streamlit) (2022.9.24)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.6.0 in /usr/local/lib/python3.8/dist-packages (from rich>=10.11.0->streamlit) (2.6.1)\n",
            "Collecting commonmark<0.10.0,>=0.9.0\n",
            "  Downloading commonmark-0.9.1-py2.py3-none-any.whl (51 kB)\n",
            "\u001b[K     |████████████████████████████████| 51 kB 7.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: decorator>=3.4.0 in /usr/local/lib/python3.8/dist-packages (from validators>=0.2->streamlit) (4.4.2)\n",
            "Building wheels for collected packages: validators\n",
            "  Building wheel for validators (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for validators: filename=validators-0.20.0-py3-none-any.whl size=19581 sha256=7d006845b418ff85da2c24700b9587caf5f242653a315eadae44324d1b9cd071\n",
            "  Stored in directory: /root/.cache/pip/wheels/19/09/72/3eb74d236bb48bd0f3c6c3c83e4e0c5bbfcbcad7c6c3539db8\n",
            "Successfully built validators\n",
            "Installing collected packages: smmap, gitdb, commonmark, watchdog, validators, semver, rich, pympler, pydeck, gitpython, blinker, streamlit\n",
            "Successfully installed blinker-1.5 commonmark-0.9.1 gitdb-4.0.10 gitpython-3.1.29 pydeck-0.8.0 pympler-1.0.1 rich-12.6.0 semver-2.13.0 smmap-5.0.0 streamlit-1.15.2 validators-0.20.0 watchdog-2.1.9\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyngrok\n",
            "  Downloading pyngrok-5.2.1.tar.gz (761 kB)\n",
            "\u001b[K     |████████████████████████████████| 761 kB 5.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: PyYAML in /usr/local/lib/python3.8/dist-packages (from pyngrok) (6.0)\n",
            "Building wheels for collected packages: pyngrok\n",
            "  Building wheel for pyngrok (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyngrok: filename=pyngrok-5.2.1-py3-none-any.whl size=19792 sha256=8ba73c3220c940a1a435c5a1f22719079b17aebe4d421c8afc0beffc6c6a8c69\n",
            "  Stored in directory: /root/.cache/pip/wheels/5d/f2/70/526da675d32f17577ec47ac4c663084efe39d47c826b6c3bb1\n",
            "Successfully built pyngrok\n",
            "Installing collected packages: pyngrok\n",
            "Successfully installed pyngrok-5.2.1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "#importing necessary modules\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.mixture import GaussianMixture as GMM\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "!pip install streamlit\n",
        "!pip install pyngrok\n",
        "\n",
        "import streamlit as st\n",
        "import pickle\n",
        "import nltk\n",
        "import string\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "\n",
        "\n",
        "\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZXLDDlQzJX6a"
      },
      "outputs": [],
      "source": [
        "#reading csv file\n",
        "df=pd.read_csv(\"/content/drive/MyDrive/ds3_project/Stock Headlines.csv\", encoding= 'unicode_escape')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t3BipP-9J07o",
        "outputId": "9a4c68f5-7c4e-47ed-b1a6-8c3a72a4699d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NULL values in each attribute before dropping Date       0\n",
            "Label     48\n",
            "Top1      52\n",
            "Top2      60\n",
            "Top3      70\n",
            "Top4      93\n",
            "Top5     104\n",
            "Top6     111\n",
            "Top7     118\n",
            "Top8     127\n",
            "Top9     135\n",
            "Top10    144\n",
            "Top11    156\n",
            "Top12    162\n",
            "Top13    171\n",
            "Top14    179\n",
            "Top15    187\n",
            "Top16    191\n",
            "Top17    198\n",
            "Top18    208\n",
            "Top19    213\n",
            "Top20    222\n",
            "Top21    232\n",
            "Top22    246\n",
            "Top23    252\n",
            "Top24    256\n",
            "Top25    258\n",
            "dtype: int64\n",
            "NULL values in each attribute after dropping Date     0\n",
            "Label    0\n",
            "Top1     0\n",
            "Top2     0\n",
            "Top3     0\n",
            "Top4     0\n",
            "Top5     0\n",
            "Top6     0\n",
            "Top7     0\n",
            "Top8     0\n",
            "Top9     0\n",
            "Top10    0\n",
            "Top11    0\n",
            "Top12    0\n",
            "Top13    0\n",
            "Top14    0\n",
            "Top15    0\n",
            "Top16    0\n",
            "Top17    0\n",
            "Top18    0\n",
            "Top19    0\n",
            "Top20    0\n",
            "Top21    0\n",
            "Top22    0\n",
            "Top23    0\n",
            "Top24    0\n",
            "Top25    0\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "#dropping NULL values in dataset\n",
        "Noe=df.isnull().sum()\n",
        "print(\"NULL values in each attribute before dropping\",Noe)\n",
        "df = df.dropna(axis=0)\n",
        "\n",
        "Noe=df.isnull().sum()\n",
        "print(\"NULL values in each attribute after dropping\",Noe)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c0qXZt98HZKJ",
        "outputId": "1394a0a6-783c-44c4-de2a-9cb1422e2b1d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/frame.py:5238: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  return super().replace(\n"
          ]
        }
      ],
      "source": [
        "# splitting train and test data\n",
        "train = df[df['Date'] < '20150101']\n",
        "test = df[df['Date'] > '20141231']\n",
        "\n",
        "\n",
        "# removing punctuations\n",
        "data=train.iloc[:,2:27]\n",
        "data.replace(\"[^a-zA-Z]\",\" \",regex=True, inplace=True)\n",
        "data1=test.iloc[:,2:27]\n",
        "data1.replace(\"[^a-zA-Z]\",\" \",regex=True, inplace=True)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5GN6y-CaK_P1",
        "outputId": "b1193be2-b3e8-495e-ec31-18440908f28a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-8-f4efab44752e>:7: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data[index]=data[index].str.lower()\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "list1= [i for i in range(25)]\n",
        "new_Index=[str(i) for i in list1]\n",
        "data.columns= new_Index\n",
        "data.head(5)\n",
        "# Convertng headlines to lower case\n",
        "for index in new_Index:\n",
        "    data[index]=data[index].str.lower()\n",
        "\n",
        "data.head(1)\n",
        "\n",
        "headlines = []\n",
        "for row in range(0,len(data.index)):\n",
        "\n",
        "    headlines.append(' '.join(str(x) for x in data.iloc[row,0:25]))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qni2jyIt7-2n",
        "outputId": "92a53188-c68b-469b-ad42-91e32ba15bb9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-9-ea98fd7a9bdc>:7: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data1[index]=data1[index].str.lower()\n"
          ]
        }
      ],
      "source": [
        "list2= [i for i in range(25)]\n",
        "new_Index=[str(i) for i in list2]\n",
        "data1.columns= new_Index\n",
        "data1.head(5)\n",
        "# Convertng headlines to lower case\n",
        "for index in new_Index:\n",
        "    data1[index]=data1[index].str.lower()\n",
        "\n",
        "\n",
        "headlines1 = []\n",
        "for row in range(0,len(data1.index)):\n",
        "\n",
        "    headlines1.append(' '.join(str(x) for x in data1.iloc[row,0:25]))\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kf8K4Pr2LRXb"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a790sGR0LRiY",
        "outputId": "58d2a95b-3835-4411-e0eb-8133984bfdd2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3878"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "headlines\n",
        "len(headlines)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UworMAA-3uGN"
      },
      "outputs": [],
      "source": [
        "w_tokenizer = nltk.tokenize.WhitespaceTokenizer()\n",
        "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
        "X=[]\n",
        "#ps = PorterStemmer()\n",
        "for x in headlines:\n",
        "    #tokens=(word_tokenize(x))\n",
        "    tokens=w_tokenizer.tokenize(x)\n",
        "    lemma=[]\n",
        "    for token in tokens:\n",
        "     lemma_word=lemmatizer.lemmatize(token)\n",
        "     #stemmed_word = ps.stem(token)\n",
        "     lemma.append(lemma_word)\n",
        "    X.append(lemma)\n",
        "Y=[]\n",
        "for j in X:\n",
        "    Y.append(' '.join(j))\n",
        "#print(Y[0])\n",
        "Y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HloYp9xq3ztD",
        "outputId": "208baa32-1022-4757-df76-dd12885bcde3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3878"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Y\n",
        "len(Y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HLiLeIiD8p0S"
      },
      "outputs": [],
      "source": [
        "X1=[]\n",
        "#ps = PorterStemmer()\n",
        "for x in headlines1:\n",
        "    #tokens=(word_tokenize(x))\n",
        "    tokens=w_tokenizer.tokenize(x)\n",
        "    lemma=[]\n",
        "    for token in tokens:\n",
        "     lemma_word=lemmatizer.lemmatize(token)\n",
        "     #stemmed_word = ps.stem(token)\n",
        "     lemma.append(lemma_word)\n",
        "    X1.append(lemma)\n",
        "Y1=[]\n",
        "for j in X1:\n",
        "    Y1.append(' '.join(j))\n",
        "#print(Y[0])\n",
        "Y1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JtJU52kWLSdu",
        "outputId": "661f47a5-0ddf-466e-dc02-106941f31611"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "scipy.sparse.csr.csr_matrix"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "countvector=CountVectorizer(ngram_range=(2,2))\n",
        "traindataset1=countvector.fit_transform(Y)\n",
        "type(traindataset1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8vFBHzk6JyDU"
      },
      "outputs": [],
      "source": [
        "## implement BAG OF WORDS\n",
        "tfidfvector=TfidfVectorizer(ngram_range=(2,2))\n",
        "traindataset=tfidfvector.fit_transform(Y)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HxaU1bMnJx2i"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DQNAj3cjLcVP",
        "outputId": "9495ae69-ca8b-4bfd-fee1-c816e3c21dae"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['1', '0', '0', '1', '1', '0', '0', '0', '0', '0', '1', '1', '1',\n",
              "       '1', '0', '1', '0', '0', '1', '0', '1', '1', '1', '1', '0', '0',\n",
              "       '1', '0', '1', '1', '1', '0', '0', '1', '0', '1', '1', '0', '0',\n",
              "       '1', '0', '0', '1', '0', '1', '0', '0', '1', '0', '1', '0', '1',\n",
              "       '0', '1', '0', '0', '0', '0', '1', '1', '0', '0', '1', '1', '0',\n",
              "       '1', '1', '1', '0', '1', '1', '0', '0', '1', '0', '1', '1', '1',\n",
              "       '0', '1', '0', '0', '1', '1', '0', '0', '1', '1', '0', '0', '0',\n",
              "       '1', '1', '1', '1', '0', '1', '0', '0', '1', '0', '0', '1', '0',\n",
              "       '1', '0', '0', '0', '0', '1', '1', '0', '0', '1', '1', '1', '0',\n",
              "       '1', '1', '0', '0', '1', '0', '1', '1', '0', '0', '1', '0', '1',\n",
              "       '1', '1', '1', '0', '1', '0', '1', '0', '0', '0', '0', '0', '1',\n",
              "       '1', '0', '0', '0', '0', '0', '0', '0', '1', '0', '0', '1', '1',\n",
              "       '1', '0', '0', '0', '0', '0', '0', '1', '1', '0', '0', '0', '1',\n",
              "       '1', '0', '1', '0', '1', '1', '0', '1', '1', '0', '0', '1', '0',\n",
              "       '0', '0', '1', '0', '1', '1', '0', '1', '1', '1', '1', '1', '1',\n",
              "       '1', '0', '0', '1', '1', '1', '0', '0', '1', '1', '0', '0', '1',\n",
              "       '0', '0', '1', '1', '0', '0', '1', '0', '1', '0', '0', '0', '1',\n",
              "       '1', '1', '0', '1', '0', '1', '1', '0', '0', '1', '0', '0', '1',\n",
              "       '0', '0', '0', '1', '0', '1', '1', '1', '0', '0', '1', '1', '1',\n",
              "       '0', '0', '1', '0', '0', '1', '1', '1', '1', '1', '1', '1', '1',\n",
              "       '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1',\n",
              "       '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1',\n",
              "       '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1',\n",
              "       '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1',\n",
              "       '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1',\n",
              "       '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1',\n",
              "       '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1',\n",
              "       '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1',\n",
              "       '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1',\n",
              "       '1'], dtype='<U1')"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "naive=MultinomialNB()\n",
        "naive.fit(traindataset,train['Label'])\n",
        "\n",
        "test_transform= []\n",
        "for row in range(0,len(test.index)):\n",
        "    test_transform.append(' '.join(str(x) for x in test.iloc[row,2:27]))\n",
        "test_dataset = tfidfvector.transform(Y1)\n",
        "predictions1 = naive.predict(test_dataset)\n",
        "\n",
        "predictions1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qUxzbvJMz0Kz",
        "outputId": "af0fc0be-2203-42d0-e631-9266ad97283b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['1', '0', '1', '1', '1', '0', '0', '0', '1', '1', '1', '1', '1',\n",
              "       '1', '1', '1', '0', '0', '1', '1', '1', '1', '1', '1', '0', '0',\n",
              "       '1', '1', '1', '1', '1', '1', '0', '1', '1', '1', '1', '0', '1',\n",
              "       '1', '0', '0', '1', '0', '1', '0', '0', '1', '0', '1', '1', '1',\n",
              "       '0', '1', '1', '0', '0', '0', '1', '1', '0', '0', '1', '1', '1',\n",
              "       '1', '1', '1', '0', '1', '1', '1', '0', '1', '1', '1', '1', '1',\n",
              "       '1', '1', '0', '0', '1', '1', '1', '0', '1', '1', '0', '1', '0',\n",
              "       '1', '1', '1', '1', '0', '1', '0', '0', '1', '1', '0', '1', '0',\n",
              "       '1', '0', '0', '0', '0', '1', '1', '0', '1', '1', '1', '1', '0',\n",
              "       '1', '1', '1', '1', '1', '0', '1', '1', '0', '1', '1', '1', '1',\n",
              "       '1', '1', '1', '0', '1', '0', '1', '0', '0', '0', '0', '0', '1',\n",
              "       '1', '0', '1', '0', '0', '0', '0', '0', '1', '1', '0', '1', '1',\n",
              "       '1', '0', '0', '0', '0', '0', '1', '1', '1', '0', '1', '1', '1',\n",
              "       '0', '1', '1', '0', '1', '1', '1', '1', '1', '0', '0', '1', '0',\n",
              "       '0', '0', '1', '1', '1', '1', '0', '1', '1', '1', '1', '1', '1',\n",
              "       '1', '0', '0', '1', '1', '1', '0', '0', '1', '1', '0', '0', '1',\n",
              "       '0', '0', '1', '1', '0', '0', '1', '0', '1', '0', '0', '1', '1',\n",
              "       '1', '1', '0', '1', '0', '1', '1', '0', '0', '1', '0', '1', '1',\n",
              "       '1', '0', '1', '1', '1', '1', '1', '1', '1', '0', '1', '1', '1',\n",
              "       '0', '1', '1', '1', '0', '0', '0', '1', '1', '1', '1', '0', '1',\n",
              "       '1', '1', '1', '1', '1', '0', '1', '1', '1', '1', '1', '1', '0',\n",
              "       '1', '1', '1', '0', '0', '0', '1', '0', '1', '1', '1', '1', '1',\n",
              "       '0', '1', '1', '1', '1', '1', '1', '1', '0', '0', '0', '1', '0',\n",
              "       '0', '1', '1', '1', '1', '0', '1', '1', '1', '1', '1', '0', '1',\n",
              "       '1', '0', '0', '1', '0', '0', '1', '0', '0', '1', '1', '1', '1',\n",
              "       '1', '1', '1', '1', '0', '1', '1', '1', '1', '1', '1', '0', '1',\n",
              "       '0', '1', '1', '1', '1', '1', '1', '1', '1', '1', '0', '0', '0',\n",
              "       '0', '1', '1', '1', '1', '1', '0', '1', '1', '0', '1', '1', '1',\n",
              "       '0', '1', '0', '1', '1', '0', '0', '0', '0', '1', '1', '1', '1',\n",
              "       '1'], dtype=object)"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = XGBClassifier()\n",
        "model.fit(traindataset,train['Label'])\n",
        "predictions2 = model.predict(test_dataset)\n",
        "predictions2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "km-Wm2b4-zII"
      },
      "outputs": [],
      "source": [
        "# implement RandomForest Classifier\n",
        "randomclassifier=RandomForestClassifier(n_estimators=200,criterion='entropy')\n",
        "randomclassifier.fit(traindataset,train['Label'])\n",
        "\n",
        "predictions3 = randomclassifier.predict(test_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ooKDBhluxeHX",
        "outputId": "100c2ae4-3619-42f3-c6f3-2c56d15ba3d2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['1', '0', '0', '1', '1', '0', '0', '0', '0', '0', '1', '1', '1',\n",
              "       '1', '0', '1', '0', '0', '1', '0', '1', '1', '1', '1', '0', '0',\n",
              "       '1', '0', '1', '1', '1', '0', '0', '1', '0', '1', '1', '0', '0',\n",
              "       '1', '0', '0', '1', '0', '1', '0', '0', '1', '0', '1', '0', '1',\n",
              "       '0', '1', '0', '0', '0', '0', '1', '1', '0', '0', '1', '1', '0',\n",
              "       '1', '1', '1', '0', '1', '1', '0', '0', '1', '0', '1', '1', '1',\n",
              "       '0', '1', '0', '0', '1', '1', '0', '0', '1', '1', '0', '0', '0',\n",
              "       '1', '1', '1', '1', '0', '1', '0', '0', '1', '0', '0', '1', '0',\n",
              "       '1', '0', '0', '0', '0', '1', '1', '0', '0', '1', '1', '1', '0',\n",
              "       '1', '1', '0', '0', '1', '0', '1', '1', '0', '0', '1', '0', '1',\n",
              "       '1', '1', '1', '0', '1', '0', '1', '0', '0', '0', '0', '0', '1',\n",
              "       '1', '0', '0', '0', '0', '0', '0', '0', '1', '0', '0', '1', '1',\n",
              "       '1', '0', '0', '0', '0', '0', '0', '1', '1', '0', '0', '0', '1',\n",
              "       '1', '0', '1', '0', '1', '1', '0', '1', '1', '0', '0', '1', '0',\n",
              "       '0', '0', '1', '0', '1', '1', '0', '1', '1', '1', '1', '1', '1',\n",
              "       '1', '0', '0', '1', '1', '1', '0', '0', '1', '1', '0', '0', '1',\n",
              "       '0', '0', '1', '1', '0', '0', '1', '0', '1', '0', '0', '0', '1',\n",
              "       '1', '1', '0', '1', '0', '1', '1', '0', '0', '1', '0', '0', '1',\n",
              "       '0', '0', '0', '1', '0', '1', '1', '1', '0', '0', '1', '1', '1',\n",
              "       '0', '0', '1', '0', '0', '1', '1', '1', '1', '1', '1', '1', '1',\n",
              "       '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1',\n",
              "       '1', '1', '1', '0', '0', '1', '1', '1', '1', '1', '1', '1', '1',\n",
              "       '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1',\n",
              "       '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1',\n",
              "       '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1',\n",
              "       '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1',\n",
              "       '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1',\n",
              "       '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1',\n",
              "       '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1',\n",
              "       '1'], dtype=object)"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "classifier = LogisticRegression(random_state = 0)\n",
        "classifier.fit(traindataset,train['Label'])\n",
        "predictions4=classifier.predict(test_dataset)\n",
        "predictions4\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Y8w_q-iKT4O"
      },
      "outputs": [],
      "source": [
        "# Using K-means\n",
        "knn5 = KNeighborsClassifier(n_neighbors=5)\n",
        "knn5.fit(traindataset,train['Label'])\n",
        "predictions5= knn5.predict(test_dataset)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 169
        },
        "id": "RJF18emZ8GdZ",
        "outputId": "18f600be-3960-42cf-ea21-1fdf0d4c37d5"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-d1a4e00d2c47>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredictions2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'predictions2' is not defined"
          ]
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kbxxZTZD_pVl",
        "outputId": "42741e0c-e28d-4085-f200-5871e3017b44"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[130  56]\n",
            " [  0 192]]\n",
            "0.8518518518518519\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.70      0.82       186\n",
            "           1       0.77      1.00      0.87       192\n",
            "\n",
            "    accuracy                           0.85       378\n",
            "   macro avg       0.89      0.85      0.85       378\n",
            "weighted avg       0.89      0.85      0.85       378\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#for naive bayes\n",
        "matrix=confusion_matrix(test['Label'],predictions1)\n",
        "print(matrix)\n",
        "score=accuracy_score(test['Label'],predictions1)\n",
        "print(score)\n",
        "report=classification_report(test['Label'],predictions1)\n",
        "print(report)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gqjkK_dhXmLI",
        "outputId": "eb03598a-c6d0-49c9-fcd0-b851ac28d5bf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[109  77]\n",
            " [ 21 171]]\n",
            "0.7407407407407407\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.59      0.69       186\n",
            "           1       0.69      0.89      0.78       192\n",
            "\n",
            "    accuracy                           0.74       378\n",
            "   macro avg       0.76      0.74      0.73       378\n",
            "weighted avg       0.76      0.74      0.73       378\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# for xgboost\n",
        "matrix=confusion_matrix(test['Label'],predictions2)\n",
        "print(matrix)\n",
        "score=accuracy_score(test['Label'],predictions2)\n",
        "print(score)\n",
        "report=classification_report(test['Label'],predictions2)\n",
        "print(report)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fs12QIQKXl_a",
        "outputId": "67f978c9-014e-4a87-b648-d62235d7a931"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[151  35]\n",
            " [ 20 172]]\n",
            "0.8544973544973545\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.81      0.85       186\n",
            "           1       0.83      0.90      0.86       192\n",
            "\n",
            "    accuracy                           0.85       378\n",
            "   macro avg       0.86      0.85      0.85       378\n",
            "weighted avg       0.86      0.85      0.85       378\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# for random forest\n",
        "matrix=confusion_matrix(test['Label'],predictions3)\n",
        "print(matrix)\n",
        "score=accuracy_score(test['Label'],predictions3)\n",
        "print(score)\n",
        "report=classification_report(test['Label'],predictions3)\n",
        "print(report)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9_pAWBbKXly6",
        "outputId": "9c45cb6b-0024-4d55-e00c-005bd151ee6d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[132  54]\n",
            " [  0 192]]\n",
            "0.8571428571428571\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.71      0.83       186\n",
            "           1       0.78      1.00      0.88       192\n",
            "\n",
            "    accuracy                           0.86       378\n",
            "   macro avg       0.89      0.85      0.85       378\n",
            "weighted avg       0.89      0.86      0.85       378\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# for logistic regression\n",
        "matrix=confusion_matrix(test['Label'],predictions4)\n",
        "print(matrix)\n",
        "score=accuracy_score(test['Label'],predictions4)\n",
        "print(score)\n",
        "report=classification_report(test['Label'],predictions4)\n",
        "print(report)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_BkwynQp-pT2",
        "outputId": "c6e7dff1-e18d-46c6-8730-7b61bed4e677"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[106  80]\n",
            " [ 58 134]]\n",
            "0.6349206349206349\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.65      0.57      0.61       186\n",
            "           1       0.63      0.70      0.66       192\n",
            "\n",
            "    accuracy                           0.63       378\n",
            "   macro avg       0.64      0.63      0.63       378\n",
            "weighted avg       0.64      0.63      0.63       378\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# for knn\n",
        "matrix=confusion_matrix(test['Label'],predictions5)\n",
        "print(matrix)\n",
        "score=accuracy_score(test['Label'],predictions5)\n",
        "print(score)\n",
        "report=classification_report(test['Label'],predictions5)\n",
        "print(report)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8q_Z6NTuWq47",
        "outputId": "e96b1231-214d-4194-92cf-54a24cbce1e1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing app.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "st.title('Stock sentiment analysis')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8GU_92o26tL6"
      },
      "outputs": [],
      "source": [
        "if st.button('Predict'):\n",
        "  st.header(predictions1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LlQ02i0v6tGm"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KRSE5qO-6s8_",
        "outputId": "424baf14-2fe3-4ada-e82d-02c2caa5efde"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Authtoken saved to configuration file: /root/.ngrok2/ngrok.yml\n"
          ]
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kYlvDR7N-OPb",
        "outputId": "12c74187-0969-44e8-fc1a-2f4efc1aece0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NAME:\n",
            "   ngrok - tunnel local ports to public URLs and inspect traffic\n",
            "\n",
            "DESCRIPTION:\n",
            "    ngrok exposes local networked services behinds NATs and firewalls to the\n",
            "    public internet over a secure tunnel. Share local websites, build/test\n",
            "    webhook consumers and self-host personal services.\n",
            "    Detailed help for each command is available with 'ngrok help <command>'.\n",
            "    Open http://localhost:4040 for ngrok's web interface to inspect traffic.\n",
            "\n",
            "EXAMPLES:\n",
            "    ngrok http 80                    # secure public URL for port 80 web server\n",
            "    ngrok http -subdomain=baz 8080   # port 8080 available at baz.ngrok.io\n",
            "    ngrok http foo.dev:80            # tunnel to host:port instead of localhost\n",
            "    ngrok http https://localhost     # expose a local https server\n",
            "    ngrok tcp 22                     # tunnel arbitrary TCP traffic to port 22\n",
            "    ngrok tls -hostname=foo.com 443  # TLS traffic for foo.com to port 443\n",
            "    ngrok start foo bar baz          # start tunnels from the configuration file\n",
            "\n",
            "VERSION:\n",
            "   2.3.40\n",
            "\n",
            "AUTHOR:\n",
            "  inconshreveable - <alan@ngrok.com>\n",
            "\n",
            "COMMANDS:\n",
            "   authtoken\tsave authtoken to configuration file\n",
            "   credits\tprints author and licensing information\n",
            "   http\t\tstart an HTTP tunnel\n",
            "   start\tstart tunnels by name from the configuration file\n",
            "   tcp\t\tstart a TCP tunnel\n",
            "   tls\t\tstart a TLS tunnel\n",
            "   update\tupdate ngrok to the latest version\n",
            "   version\tprint the version string\n",
            "   help\t\tShows a list of commands or help for one command\n",
            "\n",
            "PYNGROK VERSION:\n",
            "   5.2.1\n"
          ]
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MRmoAUt1-Y7A"
      },
      "outputs": [],
      "source": [
        "#from pyngrok import ngrok"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "zsaC0uGHCVot",
        "outputId": "e4f07084-2270-4678-9765-bb3121ed327a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[..................] \\ fetchMetadata: sill resolveWithNewModule localtunnel@2.0\u001b[0m\u001b[K\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to False.\n",
            "\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8502\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://104.196.137.191:8502\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[K\u001b[?25hnpx: installed 22 in 4.576s\n",
            "your url is: https://silent-bats-cheer-104-196-137-191.loca.lt\n"
          ]
        }
      ],
      "source": [
        "!streamlit run app.py & npx localtunnel --port 8501\n",
        "#! nohup streamlit run app.py &"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6POYKzLaCkKL",
        "outputId": "9f15b117-4392-4c26-d99c-c2c367408b69"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "731\n",
            "806\n"
          ]
        }
      ],
      "source": [
        "#!pgrep streamlit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FAppaOSfB16G",
        "outputId": "1f8c39f8-a17f-467f-c1e1-e14c1c8d68fd"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:pyngrok.ngrok:Opening tunnel named: http-80-1ec2ce2b-3ab1-46db-9408-c4de441cd688\n",
            "2022-12-04 17:06:10.990 INFO    pyngrok.ngrok: Opening tunnel named: http-80-1ec2ce2b-3ab1-46db-9408-c4de441cd688\n",
            "INFO:pyngrok.process.ngrok:t=2022-12-04T17:06:11+0000 lvl=info msg=\"no configuration paths supplied\"\n",
            "2022-12-04 17:06:11.067 INFO    pyngrok.process.ngrok: t=2022-12-04T17:06:11+0000 lvl=info msg=\"no configuration paths supplied\"\n",
            "INFO:pyngrok.process.ngrok:t=2022-12-04T17:06:11+0000 lvl=info msg=\"using configuration at default config path\" path=/root/.ngrok2/ngrok.yml\n",
            "2022-12-04 17:06:11.074 INFO    pyngrok.process.ngrok: t=2022-12-04T17:06:11+0000 lvl=info msg=\"using configuration at default config path\" path=/root/.ngrok2/ngrok.yml\n",
            "INFO:pyngrok.process.ngrok:t=2022-12-04T17:06:11+0000 lvl=info msg=\"open config file\" path=/root/.ngrok2/ngrok.yml err=nil\n",
            "2022-12-04 17:06:11.078 INFO    pyngrok.process.ngrok: t=2022-12-04T17:06:11+0000 lvl=info msg=\"open config file\" path=/root/.ngrok2/ngrok.yml err=nil\n",
            "INFO:pyngrok.process.ngrok:t=2022-12-04T17:06:11+0000 lvl=info msg=\"starting web service\" obj=web addr=127.0.0.1:4040\n",
            "2022-12-04 17:06:11.081 INFO    pyngrok.process.ngrok: t=2022-12-04T17:06:11+0000 lvl=info msg=\"starting web service\" obj=web addr=127.0.0.1:4040\n",
            "INFO:pyngrok.process.ngrok:t=2022-12-04T17:06:11+0000 lvl=info msg=\"tunnel session started\" obj=tunnels.session\n",
            "2022-12-04 17:06:11.251 INFO    pyngrok.process.ngrok: t=2022-12-04T17:06:11+0000 lvl=info msg=\"tunnel session started\" obj=tunnels.session\n",
            "INFO:pyngrok.process.ngrok:t=2022-12-04T17:06:11+0000 lvl=info msg=\"client session established\" obj=csess id=caf57e3db299\n",
            "2022-12-04 17:06:11.255 INFO    pyngrok.process.ngrok: t=2022-12-04T17:06:11+0000 lvl=info msg=\"client session established\" obj=csess id=caf57e3db299\n",
            "INFO:pyngrok.process.ngrok:t=2022-12-04T17:06:11+0000 lvl=info msg=start pg=/api/tunnels id=d40518e37ff6af2d\n",
            "2022-12-04 17:06:11.267 INFO    pyngrok.process.ngrok: t=2022-12-04T17:06:11+0000 lvl=info msg=start pg=/api/tunnels id=d40518e37ff6af2d\n",
            "INFO:pyngrok.process.ngrok:t=2022-12-04T17:06:11+0000 lvl=info msg=end pg=/api/tunnels id=d40518e37ff6af2d status=200 dur=454.701µs\n",
            "2022-12-04 17:06:11.277 INFO    pyngrok.process.ngrok: t=2022-12-04T17:06:11+0000 lvl=info msg=end pg=/api/tunnels id=d40518e37ff6af2d status=200 dur=454.701µs\n",
            "INFO:pyngrok.process.ngrok:t=2022-12-04T17:06:11+0000 lvl=info msg=start pg=/api/tunnels id=ea7bbd5efd5a9d5b\n",
            "2022-12-04 17:06:11.282 INFO    pyngrok.process.ngrok: t=2022-12-04T17:06:11+0000 lvl=info msg=start pg=/api/tunnels id=ea7bbd5efd5a9d5b\n",
            "INFO:pyngrok.process.ngrok:t=2022-12-04T17:06:11+0000 lvl=info msg=end pg=/api/tunnels id=ea7bbd5efd5a9d5b status=200 dur=153.476µs\n",
            "2022-12-04 17:06:11.286 INFO    pyngrok.process.ngrok: t=2022-12-04T17:06:11+0000 lvl=info msg=end pg=/api/tunnels id=ea7bbd5efd5a9d5b status=200 dur=153.476µs\n",
            "INFO:pyngrok.process.ngrok:t=2022-12-04T17:06:11+0000 lvl=info msg=start pg=/api/tunnels id=10e05bd22c4168e4\n",
            "2022-12-04 17:06:11.289 INFO    pyngrok.process.ngrok: t=2022-12-04T17:06:11+0000 lvl=info msg=start pg=/api/tunnels id=10e05bd22c4168e4\n",
            "INFO:pyngrok.process.ngrok:t=2022-12-04T17:06:11+0000 lvl=info msg=\"started tunnel\" obj=tunnels name=\"http-80-1ec2ce2b-3ab1-46db-9408-c4de441cd688 (http)\" addr=http://localhost:80 url=http://8b32-104-196-137-191.ngrok.io\n",
            "2022-12-04 17:06:11.363 INFO    pyngrok.process.ngrok: t=2022-12-04T17:06:11+0000 lvl=info msg=\"started tunnel\" obj=tunnels name=\"http-80-1ec2ce2b-3ab1-46db-9408-c4de441cd688 (http)\" addr=http://localhost:80 url=http://8b32-104-196-137-191.ngrok.io\n",
            "INFO:pyngrok.process.ngrok:t=2022-12-04T17:06:11+0000 lvl=info msg=\"started tunnel\" obj=tunnels name=http-80-1ec2ce2b-3ab1-46db-9408-c4de441cd688 addr=http://localhost:80 url=https://8b32-104-196-137-191.ngrok.io\n",
            "2022-12-04 17:06:11.373 INFO    pyngrok.process.ngrok: t=2022-12-04T17:06:11+0000 lvl=info msg=\"started tunnel\" obj=tunnels name=http-80-1ec2ce2b-3ab1-46db-9408-c4de441cd688 addr=http://localhost:80 url=https://8b32-104-196-137-191.ngrok.io\n",
            "INFO:pyngrok.process.ngrok:t=2022-12-04T17:06:11+0000 lvl=info msg=end pg=/api/tunnels id=10e05bd22c4168e4 status=201 dur=90.485041ms\n",
            "2022-12-04 17:06:11.380 INFO    pyngrok.process.ngrok: t=2022-12-04T17:06:11+0000 lvl=info msg=end pg=/api/tunnels id=10e05bd22c4168e4 status=201 dur=90.485041ms\n",
            "INFO:pyngrok.process.ngrok:t=2022-12-04T17:06:11+0000 lvl=info msg=start pg=\"/api/tunnels/http-80-1ec2ce2b-3ab1-46db-9408-c4de441cd688 (http)\" id=2c7ffa979087e3d4\n",
            "2022-12-04 17:06:11.392 INFO    pyngrok.process.ngrok: t=2022-12-04T17:06:11+0000 lvl=info msg=start pg=\"/api/tunnels/http-80-1ec2ce2b-3ab1-46db-9408-c4de441cd688 (http)\" id=2c7ffa979087e3d4\n",
            "INFO:pyngrok.process.ngrok:t=2022-12-04T17:06:11+0000 lvl=info msg=end pg=\"/api/tunnels/http-80-1ec2ce2b-3ab1-46db-9408-c4de441cd688 (http)\" id=2c7ffa979087e3d4 status=200 dur=187.348µs\n",
            "2022-12-04 17:06:11.396 INFO    pyngrok.process.ngrok: t=2022-12-04T17:06:11+0000 lvl=info msg=end pg=\"/api/tunnels/http-80-1ec2ce2b-3ab1-46db-9408-c4de441cd688 (http)\" id=2c7ffa979087e3d4 status=200 dur=187.348µs\n"
          ]
        }
      ],
      "source": [
        "#url = ngrok.connect(port='8501')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k5M89m7DC1f4",
        "outputId": "d545756a-ace5-41f1-f34e-722d009b9d26"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NgrokTunnel: \"http://8b32-104-196-137-191.ngrok.io\" -> \"http://localhost:80\"\n"
          ]
        }
      ],
      "source": [
        "#print(url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jh4UsLtuB1uq"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wU5pGzgc-hSJ"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k48lB9BkWqte",
        "outputId": "4b4973fe-5057-4810-c054-c7f29222726e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Usage: streamlit run [OPTIONS] TARGET [ARGS]...\n",
            "\n",
            "Error: Streamlit requires raw Python (.py) files, not .ipynb.\n",
            "For more information, please see https://docs.streamlit.io\n"
          ]
        }
      ],
      "source": [
        "!streamlit run STOCK_SHARE_PREDICTOR.ipy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RvFF9XwDYjIt"
      },
      "source": [
        "# New section"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}